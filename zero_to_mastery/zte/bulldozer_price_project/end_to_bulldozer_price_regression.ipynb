{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d089b8-7c05-4e4f-96e9-05394bf1f01c",
   "metadata": {},
   "source": [
    "# Predicting the Sale Price of Bullzoders using Machine Learning\n",
    "\n",
    "in this notebook, we are going to go through an example of a machine \n",
    "learning project with the goal of predicting the sale price of \n",
    "bulldozers.\n",
    "\n",
    "## 1. Problem definition\n",
    "> How well can we predict the future sales price of a bulldozer, given its characteristics and previous examples of how much similar bulldozers have been sold for?\n",
    "\n",
    "## 2. Data\n",
    "The data is downloaded from the Kaggle Bluebook for Bulldozers competition: https://www.kaggle.com/c/bluebook-for-bulldozers/data\n",
    "\n",
    "There are 3 main datasets: \n",
    "\n",
    "* Train.csv is the training set, which contains data through the end of 2011.\n",
    "* \n",
    "Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of   the competition. Your score on this set is used to create the public leaderboard.* \n",
    "Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. You       r score on the test set determines your final rank for the competitio\n",
    "  n.\n",
    "## 3. Evaluatno\n",
    "The evaluation metric for this competition is the RMSLE (root mean squared log error) between the actual and predicted auction prices.\n",
    "\n",
    "For more on the evaluation of this project check: www.kaggle.com/competitions/bluebook-for-bulldozers/overview/evaluation \n",
    "\n",
    "**Note:** the goal for most regression evaluation metrics is to minimize the error. For example our goal for this project will be to build a machine learning model which minimizes RMSLE.\n",
    "n\n",
    "\n",
    "## 4. Featur\n",
    "\n",
    "Kaggle provides a data dictionary detailing all of the features of the dataset. You can view this data on excel: https://www.kaggle.com/c/bluebook-for-bulldozers/data?select=Data+Dictionary.xlsx\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc453a-408a-4187-bd6c-ca5363ff1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e9763-ab65-49c6-a483-2e1cc53514af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training and validation sets\n",
    "df = pd.read_csv(\"data/bluebook-for-bulldozers/TrainAndValid.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425c2aa-c0b7-4307-91fd-bbb3431b823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d958b0-95b3-47da-8876-78adb200308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ad9be-09a8-40af-82d7-ac4a5b5562c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df[\"saledate\"][:1000], df[\"SalePrice\"][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07afa06b-3cc1-4e20-be6e-58703fb45fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a72f5-eae6-40b0-aaa9-b4fe5aa89fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SalePrice.plot.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4803bae-352d-41b2-b188-4468aa244cf0",
   "metadata": {},
   "source": [
    "### Parsing dates\n",
    "\n",
    "When we work with time series data, we would like to enrich the time & date component as much as possible.\n",
    "\n",
    "We can do that by telling pandas which of our columns has dates in it using the `parse_dates` parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a0d60-0d9f-438d-b869-2d60d3c5d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data again but this time parse dates\n",
    "df = pd.read_csv(\"data/bluebook-for-bulldozers/TrainAndValid.csv\", low_memory=False, parse_dates=[\"saledate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a40acd-67ee-477e-8be4-ec4578184d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6356df59-cea8-4a77-9be3-cba9d2a1f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"saledate\"][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e75678-18a1-45c7-b368-d1d23dfa93c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df[\"saledate\"][:1000], df[\"SalePrice\"][:1000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34499867-11b2-4ebb-87ef-6735b4f298db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5ad22-72da-4473-bbc6-5f7a43f2ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose to view all the columns individually\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf72f08-b373-4bb9-bcc6-e0d58922218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fda6ae-e5b4-4cb8-90de-6a73d81807a3",
   "metadata": {},
   "source": [
    "### Sort DataFrame by saledate \n",
    "\n",
    "When working with time series data, it is a good idea to sort it by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9014197-d81c-4f2c-94c4-382798d7e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DataFrame in date order\n",
    "df.sort_values(by=[\"saledate\"], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b901046f-d9c6-4ffb-aed9-12d40bf8437c",
   "metadata": {},
   "source": [
    "### Make a copy of original DataFrame\n",
    "\n",
    "We make a copy of the original dataframe, so upon manipulation of the dataset we still have original unadultrated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8dccaf-b6db-43e7-8748-2c4801a8ab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy\n",
    "df_tmp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690771d0-232b-4d2a-886a-fe436d250eba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tmp[\"saledate\"][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caefc01-1ee2-45f4-8cf0-20f1c9715876",
   "metadata": {},
   "source": [
    "### Add datetime parameters for `saledate` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12370d24-16e6-47aa-84dc-07745dfb7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[:1].saledate.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6924af56-4f5b-4841-932a-581394035cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[:1].saledate.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c0514d-d9cc-4017-8f3b-a0c4dddf6211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[:1].saledate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee459ea9-72df-4b3b-8c6d-5876ac86963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"saleYear\"] = df_tmp.saledate.dt.year\n",
    "df_tmp[\"saleMonth\"] = df_tmp.saledate.dt.month\n",
    "df_tmp[\"saleDay\"]= df_tmp.saledate.dt.day\n",
    "df_tmp[\"saleDayOfWeek\"]= df_tmp.saledate.dt.dayofweek\n",
    "df_tmp[\"saleDayOfYear\"]= df_tmp.saledate.dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a096b1-bbc6-4be9-8749-1c90ddf12113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[:2].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d539868a-eddf-4aee-ab39-527531fbdc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have enriched our Dataframe with data time features, we can drop the redundant `saledate` column\n",
    "df_tmp.drop(\"saledate\", axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1434a82c-a652-4ad9-b1c1-2f9bc0f89233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eb8bb2-dcd5-47da-9cb6-e0c722019db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the values of different columns\n",
    "df_tmp.state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee2051e-5929-4c5b-8b95-1233bd20e41b",
   "metadata": {},
   "source": [
    "## 5. Modelling\n",
    "\n",
    "We have done some EDA,but we can do more, however we can try doing some model driven EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614fcd54-0d8a-4421-b859-5f73aab6d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let us check the DataFrame, we are trying to determine SalePrice, \n",
    "# using other columns as features, so let us allocate SalePrice as X column first.\n",
    "# Using the scikit learn machine learning map on https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "# We can see we want to predict a quatity so we can classify this problem as a regression problem\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a5d3a-7af8-496e-966f-63d558d1fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build a machine learning model. see https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn-ensemble-randomforestregressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_jobs=-1, # n_jobs=-1 using as many cores on computer to speed up processing on 412698 rows of data\n",
    "                              random_state=42)\n",
    "model.fit(df_tmp.drop(\"SalesPrice\",axis=1),df_tmp[\"SalesPrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636dd484-e1f7-455e-ae56-52dba2d97a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we cant start modelling if any of our column datatypes are not numerical datatypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37bccaf-79ae-455a-b716-2e415c056ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example\n",
    "df_tmp[\"UsageBand\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d1210-7fa1-4e0f-bf6a-99ae9b65675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also we cant perform modeling if there are missing data in the columns\n",
    "df_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7bb4f-50c9-4607-aeb7-e031b1f30373",
   "metadata": {},
   "source": [
    "### Convert the String datatypes into categories\n",
    "\n",
    "One way to turn all our data into numbers is by converting them into pandas categories\n",
    "We can check out the different datatypes compatible with pandas here\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.api.types.pandas_dtype.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0657055-9e91-4d35-997a-9bdbc8dbc010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3017d5e-83aa-4bf7-b67d-d19da28e5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.api.types.is_object_dtype(df_tmp[\"UsageBand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546d535-f17f-44f8-a18e-7404f161a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the columns which contain strings\n",
    "for label,content in df_tmp.items():\n",
    "    if pd.api.types.is_object_dtype(content):\n",
    "        print(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff411bba-7b2b-4d4f-bb63-b2308b1ecd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will turn all the string values into categories\n",
    "for label,content in df_tmp.items():\n",
    "    if pd.api.types.is_object_dtype(content):\n",
    "        df_tmp[label]= content.astype(\"category\").cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462127cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will turn all of the string values into category values\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        df_tmp[label]=content.astype(\"category\").cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53b1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.state.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207cc9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.state.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff049c5",
   "metadata": {},
   "source": [
    "Thanks to pandas categories we now have a way to access all of our data in form of numbers.\n",
    "\n",
    "But we still need to fix the issue of missing data from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15166a-5120-4730-b9de-89bbe6dbe5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing data\n",
    "df_tmp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a9d07-2497-4e8b-9722-9dc68ca9e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View as a % of missing data\n",
    "df_tmp.isnull().sum()/len(df_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8d75d4",
   "metadata": {},
   "source": [
    "## Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca29b4b-710d-4617-8039-bb53a0ee90ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export current tmp dataframe\n",
    "df_tmp.to_csv(\"data/bluebook-for-bulldozers/train_tmp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c31ccd-def2-4e2a-900a-d8f33510f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessed data\n",
    "df_tmp = pd.read_csv(\"data/bluebook-for-bulldozers/train_tmp.csv\", low_memory=False)\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb972b-86f5-4e0c-87d5-ccc6f772beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eb02d8",
   "metadata": {},
   "source": [
    "## Fill missing values\n",
    "\n",
    "### Fill numeric missing values first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eaf988-c14d-49a7-9981-4dac64247aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label,content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b020fde-e81f-4ee7-a852-14a78dcacb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.ModelID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49117e55-f223-4f9b-8a59-8ad584e5f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for which numeric columns have null values\n",
    "for label,content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb6307-605d-476b-b71e-b9d3a73b4818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill numeric rows with the median\n",
    "for label,content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            # Add a binary column which tells us if the data was missing or not\n",
    "            df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n",
    "            # Fill missing numeric values with median\n",
    "            df_tmp[label]=content.fillna(content.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43de18e-b913-4af3-ba3a-ae6bd0076bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate how median is more robust than mean\n",
    "# https://datascience.stackexchange.com/questions/46744/when-to-use-mean-vs-median#:~:text=The%20median%20is%20especially%20useful,are%20usually%20discussed%20using%20medians.\n",
    "# https://surveymethods.com/when-is-it-generally-better-to-use-median-over-mean/\n",
    "\n",
    "hundreds = np.full((1000,),100)\n",
    "hundreds_billion = np.append(hundreds,1000000000)\n",
    "np.mean(hundreds),np.mean(hundreds_billion),np.median(hundreds),np.median(hundreds_billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there's any null numeric values\n",
    "for label,contenn in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8428ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.auctioneerID_is_missing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b60954",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for columns which are not numeric\n",
    "for label,content in df_tmp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49968d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn categorical variables into numbers and fill missing\n",
    "for label,content in df_tmp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        #if pd.isnull(content).sum():\n",
    "            # Add a binary column to indicate whether sample had missing value\n",
    "            df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n",
    "            # Turn categories into numbers and add +1\n",
    "            df_tmp[label]= pd.Categorical(content).codes + 1          \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71fcded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af64ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832f5db3",
   "metadata": {},
   "source": [
    "Now that all of our data is numeric as well as our dataframe has no missing values, we should be able to build a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace3ba57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
